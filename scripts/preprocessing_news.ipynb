{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9b13e92b-f6d5-4810-8766-fe8dd49fc1aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 20/41 [02:02<02:02,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] Прогресс сохранён на 1000 новостях\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 40/41 [04:01<00:05,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] Прогресс сохранён на 2000 новостях\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [04:06<00:00,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         publish_date                                              title  \\\n",
      "0 2025-04-15 20:11:01  Прибыль Ericsson за 1 квартал превзошла прогно...   \n",
      "1 2025-04-16 00:09:50  Предварительный просмотр доходов Netflix: Брил...   \n",
      "2 2025-04-16 03:12:00  AT&T (T) Выигрывает при падении Рынка: Что Вам...   \n",
      "3 2025-04-16 08:33:16  Российский рынок растет на утренних торгах в о...   \n",
      "4 2025-04-16 08:57:33  Без драйверов для роста коррекция может законч...   \n",
      "\n",
      "                                         publication        date  sentiment  \n",
      "0  Ericsson ERIC сообщила о неоднозначных результ...  2025-04-15        0.8  \n",
      "1  На фоне волатильности Уолл-стрит большинство а...  2025-04-16        0.7  \n",
      "2  AT&T (T) завершила недавнюю торговую сессию на...  2025-04-16        0.7  \n",
      "3  Российский рынок растет во время утренней сесс...  2025-04-16        0.6  \n",
      "4  Рубль превзошел золото по доходности и стал лу...  2025-04-16        0.3  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"sk-or-v1-...\"\n",
    ")\n",
    "\n",
    "def get_batch_sentiment(texts, model=\"anthropic/claude-3.5-sonnet\"):\n",
    "    \"\"\"\n",
    "    Отправляем список новостей и получаем список чисел [-1, 1].\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "    \"Для каждой из следующих новостей оцени её тональность по шкале от 0 до 1. \"\n",
    "    \"Где 0 — исключительно негативная новость, 0.5 — нейтральная, 1 — исключительно позитивная. \"\n",
    "    \"Не добавляй текст и пояснения, верни только числа, разделённые запятыми, в том же порядке.\\n\\n\"\n",
    "    )\n",
    "\n",
    "    for i, t in enumerate(texts, 1):\n",
    "        prompt += f\"{i}) {t}\\n\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    result = resp.choices[0].message.content.strip()\n",
    "    try:\n",
    "        scores = [float(x.strip()) for x in result.split(\",\")]\n",
    "    except:\n",
    "        scores = [0.0] * len(texts)\n",
    "    return scores\n",
    "\n",
    "def add_sentiment(df, text_col=\"title\", batch_size=50, save_every=20, save_path=\"../data/raw/participants/news_sentiment.csv\"):\n",
    "    sentiments = []\n",
    "    texts = df[text_col].astype(str).tolist()\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        batch_scores = get_batch_sentiment(batch)\n",
    "        sentiments.extend(batch_scores)\n",
    "\n",
    "        if (i // batch_size + 1) % save_every == 0:\n",
    "            temp_df = df.iloc[:len(sentiments)].copy()\n",
    "            temp_df[\"sentiment\"] = sentiments\n",
    "            temp_df.to_csv(save_path, index=False)\n",
    "            print(f\"[SAVE] Прогресс сохранён на {len(sentiments)} новостях\")\n",
    "\n",
    "    df[\"sentiment\"] = sentiments\n",
    "    df.to_csv(save_path, index=False)\n",
    "    return df\n",
    "\n",
    "news = pd.read_csv(\"../data/raw/participants/news_2.csv\")\n",
    "if \"Unnamed: 0\" in news.columns:\n",
    "    news = news.drop(columns=[\"Unnamed: 0\"])\n",
    "news[\"publish_date\"] = pd.to_datetime(news[\"publish_date\"])\n",
    "news[\"date\"] = news[\"publish_date\"].dt.date\n",
    "\n",
    "news = add_sentiment(news, text_col=\"title\", batch_size=50)\n",
    "\n",
    "print(news.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3e1551ea-665e-4f60-8957-c98c36b50793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11870/4177933585.py:75: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  merged[sentiment_col] = merged[newcol].combine_first(merged[sentiment_col])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>AFLT</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-18</td>\n",
       "      <td>AFLT</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-22</td>\n",
       "      <td>AFLT</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-24</td>\n",
       "      <td>AFLT</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-27</td>\n",
       "      <td>AFLT</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker  sentiment\n",
       "0  2025-04-16   AFLT        0.6\n",
       "1  2025-04-18   AFLT        0.5\n",
       "2  2025-04-22   AFLT        0.8\n",
       "3  2025-04-24   AFLT        0.6\n",
       "4  2025-04-27   AFLT        0.7"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "news = pd.read_csv(\"../data/raw/participants/news_2.csv\")\n",
    "news = news.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")\n",
    "news[\"publish_date\"] = pd.to_datetime(news[\"publish_date\"], errors=\"coerce\")\n",
    "news[\"date\"] = news[\"publish_date\"].dt.date\n",
    "\n",
    "tickers = ['GAZP','CHMF','PHOR','MAGN','MGNT','MTSS',\n",
    "           'PLZL','SBER','VTBR','LKOH','ALRS','AFLT',\n",
    "           'MOEX','NVTK','ROSN','GMKN','RUAL','T']\n",
    "\n",
    "company_map = {\n",
    "    \"газпром\": \"GAZP\", \"газ\": \"GAZP\",\n",
    "    \"северсталь\": \"CHMF\",\n",
    "    \"фосагро\": \"PHOR\",\n",
    "    \"ммк\": \"MAGN\", \"магнитогорский металлургический комбинат\": \"MAGN\",\n",
    "    \"магнит\": \"MGNT\",\n",
    "    \"мтс\": \"MTSS\",\n",
    "    \"полюс\": \"PLZL\",\n",
    "    \"сбер\": \"SBER\", \"сбербанк\": \"SBER\",\n",
    "    \"втб\": \"VTBR\",\n",
    "    \"лукойл\": \"LKOH\",\n",
    "    \"алроса\": \"ALRS\",\n",
    "    \"аэрофлот\": \"AFLT\",\n",
    "    \"мосбиржа\": \"MOEX\", \"московская биржа\": \"MOEX\",\n",
    "    \"новатэк\": \"NVTK\",\n",
    "    \"роснефть\": \"ROSN\",\n",
    "    \"норникель\": \"GMKN\", \"гмк норильский никель\": \"GMKN\",\n",
    "    \"русал\": \"RUAL\",\n",
    "    \"татнефть\": \"T\", \"тат\": \"T\"\n",
    "}\n",
    "\n",
    "def extract_tickers(row, company_map, n_words=1500):\n",
    "    title = str(row.get(\"title\", \"\")).lower()\n",
    "    publication = str(row.get(\"publication\", \"\")).lower()\n",
    "    first_words = \" \".join(publication.split()[:n_words])\n",
    "    text = f\"{title} {first_words}\"\n",
    "\n",
    "    found = []\n",
    "    for name, ticker in company_map.items():\n",
    "        pattern = r\"\\b\" + re.escape(name) + r\"\\w*\"\n",
    "        if re.search(pattern, text):\n",
    "            found.append(ticker)\n",
    "    return list(set(found))\n",
    "\n",
    "news[\"tickers_found\"] = news.apply(lambda r: extract_tickers(r, company_map), axis=1)\n",
    "def attach_sentiment_inplace(news, sentiment_csv_path, sentiment_col=\"sentiment\"):\n",
    "    import pandas as pd\n",
    "\n",
    "    sdf = pd.read_csv(sentiment_csv_path)\n",
    "\n",
    "    sdf[\"publish_date\"] = pd.to_datetime(sdf[\"publish_date\"], errors=\"coerce\")\n",
    "    news[\"publish_date\"] = pd.to_datetime(news[\"publish_date\"], errors=\"coerce\")\n",
    "\n",
    "    if sentiment_col not in news.columns:\n",
    "        news[sentiment_col] = pd.NA\n",
    "\n",
    "    merged = news.merge(\n",
    "        sdf[[\"publish_date\", \"title\", sentiment_col]],\n",
    "        on=[\"publish_date\", \"title\"],\n",
    "        how=\"left\",\n",
    "        validate=\"many_to_one\",\n",
    "        suffixes=(\"\", \"_new\")\n",
    "    )\n",
    "    newcol = f\"{sentiment_col}_new\"\n",
    "    if newcol in merged.columns:\n",
    "        merged[sentiment_col] = merged[newcol].combine_first(merged[sentiment_col])\n",
    "        merged = merged.drop(columns=[newcol])\n",
    "\n",
    "    return merged\n",
    "news = attach_sentiment_inplace(news, \"../data/raw/participants/news_sentiment.csv\", sentiment_col=\"sentiment\")\n",
    "df_news = news[[\"publish_date\", \"date\", \"tickers_found\", \"sentiment\"]].copy()\n",
    "import ast\n",
    "def _to_list(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip()\n",
    "        if x.startswith(\"[\") and x.endswith(\"]\"):\n",
    "            try:\n",
    "                v = ast.literal_eval(x)\n",
    "                return v if isinstance(v, list) else [str(v)]\n",
    "            except Exception:\n",
    "                return [x]\n",
    "        return [x]\n",
    "    return [x]\n",
    "\n",
    "df_news[\"tickers_found\"] = df_news[\"tickers_found\"].apply(_to_list)\n",
    "\n",
    "allowed = set(tickers)\n",
    "df_news[\"tickers_found\"] = df_news[\"tickers_found\"].apply(\n",
    "    lambda lst: [t for t in lst if t in allowed]\n",
    ")\n",
    "\n",
    "df_long = df_news.explode(\"tickers_found\")\n",
    "df_long = df_long.rename(columns={\"tickers_found\": \"ticker\"})\n",
    "df_long = df_long[df_long[\"ticker\"].notna()].reset_index(drop=True)\n",
    "df_long = df_long.sort_values([\"ticker\", \"publish_date\"]).reset_index(drop=True).drop('publish_date', axis=1)\n",
    "df_long.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
